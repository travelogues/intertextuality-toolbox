{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Loaded 949 texts'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "INPUT_FOLDER = '../../../travelogues-corpus/18th_century/books'\n",
    "\n",
    "def read_file(f):\n",
    "  with open(f, 'r') as file:\n",
    "    str = file.read()\n",
    "    ascii_only = re.sub('[^A-Za-z0-9 ]+', '', str)\n",
    "    return re.sub('\\\\s+', ' ', ascii_only)\n",
    "\n",
    "filenames = [f for f in glob.glob(INPUT_FOLDER + '**/*.txt')]\n",
    "texts = [ read_file(f) for f in filenames ]\n",
    "\n",
    "f'Loaded {len(texts)} texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_stopwords = []\n",
    "\n",
    "with open('stopwords.txt') as f:\n",
    "  extra_stopwords = f.readlines()\n",
    "  extra_stopwords = [ x.strip() for x in extra_stopwords ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package stopwords to /home/simonr/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('german')\n",
    "stop_words.extend(extra_stopwords)\n",
    "stop_words.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "# We'll do stemming to avoid duplicate variants\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stem_message(text):\n",
    "  words = word_tokenize(text)\n",
    "\n",
    "  stemmed_words = []\n",
    "  for word in words:\n",
    "    stemmed_words.append(porter.stem(word))\n",
    "    \n",
    "  # Remove stopwords here\n",
    "  clean_tokens = [w for w in stemmed_words if not w in stop_words and len(w) > 3] \n",
    "  return ' '.join(clean_tokens)\n",
    "\n",
    "cleaned_texts = []\n",
    "for text in texts:\n",
    "  # Remove punctutation\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "  cleaned_texts.append(stem_message(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/simonr/Software/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n  DeprecationWarning)\n"
    },
    {
     "data": {
      "text/plain": "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n             mean_change_tol=0.001, n_components=6, n_jobs=1,\n             n_topics=None, perp_tol=0.1, random_state=0,\n             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=25, token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "tf = vectorizer.fit_transform(cleaned_texts).toarray()\n",
    "\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "number_of_topics = 6\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)\n",
    "model.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic 0 words</th>\n      <th>Topic 0 weights</th>\n      <th>Topic 1 words</th>\n      <th>Topic 1 weights</th>\n      <th>Topic 2 words</th>\n      <th>Topic 2 weights</th>\n      <th>Topic 3 words</th>\n      <th>Topic 3 weights</th>\n      <th>Topic 4 words</th>\n      <th>Topic 4 weights</th>\n      <th>Topic 5 words</th>\n      <th>Topic 5 weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kirch</td>\n      <td>12945.7</td>\n      <td>wert</td>\n      <td>7640.8</td>\n      <td>ieht</td>\n      <td>9282.0</td>\n      <td>schiff</td>\n      <td>15659.3</td>\n      <td>schiff</td>\n      <td>21239.3</td>\n      <td>kirch</td>\n      <td>12595.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>waffer</td>\n      <td>9263.4</td>\n      <td>bach</td>\n      <td>5247.5</td>\n      <td>teht</td>\n      <td>8192.7</td>\n      <td>reis</td>\n      <td>8978.7</td>\n      <td>inel</td>\n      <td>16368.9</td>\n      <td>gott</td>\n      <td>7639.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>brief</td>\n      <td>9073.6</td>\n      <td>ufer</td>\n      <td>5052.6</td>\n      <td>dorf</td>\n      <td>7813.5</td>\n      <td>insel</td>\n      <td>8801.7</td>\n      <td>reie</td>\n      <td>13142.0</td>\n      <td>laen</td>\n      <td>7277.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>schne</td>\n      <td>7707.1</td>\n      <td>gebirg</td>\n      <td>5051.0</td>\n      <td>tehen</td>\n      <td>7445.7</td>\n      <td>waffer</td>\n      <td>8115.8</td>\n      <td>laen</td>\n      <td>11475.5</td>\n      <td>wien</td>\n      <td>7099.1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>reis</td>\n      <td>6677.0</td>\n      <td>gebrg</td>\n      <td>4844.1</td>\n      <td>kirch</td>\n      <td>7384.9</td>\n      <td>wind</td>\n      <td>6113.4</td>\n      <td>ollt</td>\n      <td>9779.7</td>\n      <td>drey</td>\n      <td>5252.4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>stehen</td>\n      <td>6569.0</td>\n      <td>farb</td>\n      <td>4633.4</td>\n      <td>verchieden</td>\n      <td>7228.7</td>\n      <td>kste</td>\n      <td>5957.5</td>\n      <td>verchieden</td>\n      <td>9435.6</td>\n      <td>buch</td>\n      <td>4933.6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>menschen</td>\n      <td>6337.0</td>\n      <td>zoll</td>\n      <td>4172.7</td>\n      <td>reie</td>\n      <td>7046.1</td>\n      <td>verschieden</td>\n      <td>5813.6</td>\n      <td>beonder</td>\n      <td>9313.8</td>\n      <td>heil</td>\n      <td>4543.6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>besond</td>\n      <td>6315.8</td>\n      <td>dorf</td>\n      <td>4063.3</td>\n      <td>flecken</td>\n      <td>6495.4</td>\n      <td>drei</td>\n      <td>5034.9</td>\n      <td>wind</td>\n      <td>9306.6</td>\n      <td>herzog</td>\n      <td>4412.8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>sieht</td>\n      <td>6225.7</td>\n      <td>drey</td>\n      <td>3296.3</td>\n      <td>meiten</td>\n      <td>6350.7</td>\n      <td>ufer</td>\n      <td>4867.6</td>\n      <td>menchen</td>\n      <td>8866.1</td>\n      <td>agen</td>\n      <td>4374.3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>steht</td>\n      <td>5971.4</td>\n      <td>faden</td>\n      <td>3240.3</td>\n      <td>drei</td>\n      <td>6314.1</td>\n      <td>inseln</td>\n      <td>4843.2</td>\n      <td>konnten</td>\n      <td>8841.3</td>\n      <td>dabey</td>\n      <td>4343.1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>schnen</td>\n      <td>5535.0</td>\n      <td>waffer</td>\n      <td>3056.0</td>\n      <td>felen</td>\n      <td>6227.5</td>\n      <td>meer</td>\n      <td>4810.5</td>\n      <td>erten</td>\n      <td>8240.0</td>\n      <td>heiligen</td>\n      <td>4281.8</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>verschieden</td>\n      <td>5377.9</td>\n      <td>gruben</td>\n      <td>3047.3</td>\n      <td>beteht</td>\n      <td>6171.9</td>\n      <td>konnten</td>\n      <td>4751.1</td>\n      <td>ineln</td>\n      <td>8234.8</td>\n      <td>italien</td>\n      <td>4187.6</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>buch</td>\n      <td>5236.0</td>\n      <td>grube</td>\n      <td>3012.9</td>\n      <td>chne</td>\n      <td>6072.4</td>\n      <td>volk</td>\n      <td>4554.7</td>\n      <td>andr</td>\n      <td>7808.6</td>\n      <td>chne</td>\n      <td>4187.4</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>nebst</td>\n      <td>5103.1</td>\n      <td>thon</td>\n      <td>2728.7</td>\n      <td>darin</td>\n      <td>6033.9</td>\n      <td>beiden</td>\n      <td>4394.2</td>\n      <td>wien</td>\n      <td>7331.4</td>\n      <td>kaier</td>\n      <td>3936.3</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>meisten</td>\n      <td>5044.1</td>\n      <td>monath</td>\n      <td>2705.9</td>\n      <td>laen</td>\n      <td>6033.0</td>\n      <td>fanden</td>\n      <td>4381.8</td>\n      <td>whrend</td>\n      <td>7032.0</td>\n      <td>beonder</td>\n      <td>3924.7</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>kloster</td>\n      <td>4887.1</td>\n      <td>sand</td>\n      <td>2630.3</td>\n      <td>beonder</td>\n      <td>5986.7</td>\n      <td>hafen</td>\n      <td>4368.1</td>\n      <td>fanden</td>\n      <td>6975.3</td>\n      <td>pabt</td>\n      <td>3860.5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>beiden</td>\n      <td>4770.7</td>\n      <td>gang</td>\n      <td>2590.9</td>\n      <td>drey</td>\n      <td>5543.9</td>\n      <td>andr</td>\n      <td>4300.8</td>\n      <td>chien</td>\n      <td>6676.6</td>\n      <td>etlich</td>\n      <td>3818.9</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>heiligen</td>\n      <td>4726.4</td>\n      <td>bltter</td>\n      <td>2590.3</td>\n      <td>meer</td>\n      <td>5503.5</td>\n      <td>drey</td>\n      <td>4193.0</td>\n      <td>bord</td>\n      <td>6334.7</td>\n      <td>brief</td>\n      <td>3816.3</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>geschicht</td>\n      <td>4714.7</td>\n      <td>weien</td>\n      <td>2564.6</td>\n      <td>hgel</td>\n      <td>5466.2</td>\n      <td>menschen</td>\n      <td>4094.6</td>\n      <td>geellchaft</td>\n      <td>6196.1</td>\n      <td>tehet</td>\n      <td>3769.6</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>kaiser</td>\n      <td>4492.6</td>\n      <td>salz</td>\n      <td>2522.5</td>\n      <td>andr</td>\n      <td>5382.5</td>\n      <td>verschiedenen</td>\n      <td>3989.8</td>\n      <td>volk</td>\n      <td>6125.8</td>\n      <td>sohn</td>\n      <td>3677.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights Topic 2 words Topic 2 weights  Topic 3 words Topic 3 weights Topic 4 words Topic 4 weights Topic 5 words Topic 5 weights\n0          kirch         12945.7          wert          7640.8          ieht          9282.0         schiff         15659.3        schiff         21239.3         kirch         12595.7\n1         waffer          9263.4          bach          5247.5          teht          8192.7           reis          8978.7          inel         16368.9          gott          7639.9\n2          brief          9073.6          ufer          5052.6          dorf          7813.5          insel          8801.7          reie         13142.0          laen          7277.7\n3          schne          7707.1        gebirg          5051.0         tehen          7445.7         waffer          8115.8          laen         11475.5          wien          7099.1\n4           reis          6677.0         gebrg          4844.1         kirch          7384.9           wind          6113.4          ollt          9779.7          drey          5252.4\n5         stehen          6569.0          farb          4633.4    verchieden          7228.7           kste          5957.5    verchieden          9435.6          buch          4933.6\n6       menschen          6337.0          zoll          4172.7          reie          7046.1    verschieden          5813.6       beonder          9313.8          heil          4543.6\n7         besond          6315.8          dorf          4063.3       flecken          6495.4           drei          5034.9          wind          9306.6        herzog          4412.8\n8          sieht          6225.7          drey          3296.3        meiten          6350.7           ufer          4867.6       menchen          8866.1          agen          4374.3\n9          steht          5971.4         faden          3240.3          drei          6314.1         inseln          4843.2       konnten          8841.3         dabey          4343.1\n10        schnen          5535.0        waffer          3056.0         felen          6227.5           meer          4810.5         erten          8240.0      heiligen          4281.8\n11   verschieden          5377.9        gruben          3047.3        beteht          6171.9        konnten          4751.1         ineln          8234.8       italien          4187.6\n12          buch          5236.0         grube          3012.9          chne          6072.4           volk          4554.7          andr          7808.6          chne          4187.4\n13         nebst          5103.1          thon          2728.7         darin          6033.9         beiden          4394.2          wien          7331.4         kaier          3936.3\n14       meisten          5044.1        monath          2705.9          laen          6033.0         fanden          4381.8        whrend          7032.0       beonder          3924.7\n15       kloster          4887.1          sand          2630.3       beonder          5986.7          hafen          4368.1        fanden          6975.3          pabt          3860.5\n16        beiden          4770.7          gang          2590.9          drey          5543.9           andr          4300.8         chien          6676.6        etlich          3818.9\n17      heiligen          4726.4        bltter          2590.3          meer          5503.5           drey          4193.0          bord          6334.7         brief          3816.3\n18     geschicht          4714.7         weien          2564.6          hgel          5466.2       menschen          4094.6    geellchaft          6196.1         tehet          3769.6\n19        kaiser          4492.6          salz          2522.5          andr          5382.5  verschiedenen          3989.8          volk          6125.8          sohn          3677.0"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)\n",
    "\n",
    "no_top_words = 20\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "display_topics(model, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}